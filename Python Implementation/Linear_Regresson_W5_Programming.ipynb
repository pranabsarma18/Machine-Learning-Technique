{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "uBUor5KWp3_Q",
        "FSDbBz7ucm_a",
        "5eh8cI4PeVEb"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pranabsarma18/Machine-Learning-Technique/blob/main/Python%20Implementation/Linear_Regresson_W5_Programming.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing the libraries"
      ],
      "metadata": {
        "id": "WT2nf7VJXHsH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 174,
      "metadata": {
        "id": "0kgvCN0n3_1p"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This assignments has two sections:\n",
        "* Linear Regression\n",
        "* Kernel Regression\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "iBY90BqPXO31"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 1:\n",
        "\n",
        "**Linear Regression**"
      ],
      "metadata": {
        "id": "X1nmn2q15Vzn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use the Boston_housing dataset for the regression problem. Run the below cell to get the following variables:\n",
        "* `Training_data` = Training data matrix of shape $(n, d)$\n",
        "* `labels` = label vector corresponding to the training data\n",
        "* `test_data` = Test data matrix of shape $(n_1, d)$ where $n_1$ is the number of examples in test dataset.\n",
        "* `test_labels` = label vector corresponding to the test data\n",
        "\n",
        "Use this dataset for the regression problem."
      ],
      "metadata": {
        "id": "aComJ_Fd5dnI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import boston_housing\n",
        "Train, test = boston_housing.load_data(seed= 111)\n",
        "Training_data, labels = Train[0], Train[1]\n",
        "Test_data, test_labels = test[0], test[1]"
      ],
      "metadata": {
        "id": "53UCtcH64nsC"
      },
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 1\n",
        "How many examples are there in the training dataset?\n",
        "\n"
      ],
      "metadata": {
        "id": "R0Dnj-Qha47p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Enter your solution here\n",
        "Training_data.shape[0]"
      ],
      "metadata": {
        "id": "vpLeerN2mGRi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b66a5810-3271-403e-cbd1-b767752bb1b5"
      },
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "404"
            ]
          },
          "metadata": {},
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 2\n",
        "How many examples are there in the test dataset?\n",
        "\n"
      ],
      "metadata": {
        "id": "ChYFPOV5b5jZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Enter your solution here\n",
        "Test_data.shape[0]"
      ],
      "metadata": {
        "id": "0XK7s98bb8PY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed1f6ff0-7d5c-4e12-a4b4-7322641b3e01"
      },
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "102"
            ]
          },
          "metadata": {},
          "execution_count": 177
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 3\n",
        "\n",
        "How many features are there in the dataset?\n",
        "\n"
      ],
      "metadata": {
        "id": "ZYLLXlAacL5c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Enter your solution here\n",
        "Training_data.shape[1]"
      ],
      "metadata": {
        "id": "rGvr9_jkO7NA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be11cdd4-fa5a-4fed-fc34-b84620e10fdf"
      },
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "metadata": {},
          "execution_count": 178
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linear regression model for the dataset ${\\mathbb{x}, y}$ is given as\n",
        "$$h_w(\\mathbb{x}) = w_1x^{1}+w_2x^{2}+...+w_dx^{d} =  \\mathbb{x}^Tw\n",
        "$$\n",
        "\n",
        "where $x^{i}$ is the $i^{th}$ feature, $\\mathbb{x}$ is the feature matrix of shape $(d, n)$ and $w = [w_1, w_2, ...w_d]^T$ is the weight vector.\n",
        "\n",
        "\n",
        "Notice that above model always pass through the origin but for a given dataset, best fit model need not pass through the origin. To tackle this issue, we add an intercept $w_0$ in the model and set the corresponding featrue $x^{0}$ to $1$. That is \n",
        "\n",
        "$$h_w(\\mathbb{x}) =w_0x^{0}+ w_1x^{1}+w_2x^{2}+...+w_dx^{n} =  \\mathbb{x}^Tw\n",
        "$$\n",
        "\n",
        "We call $x^{0}$ the dummy feature and set its value to 1 for each examples. Now $w$ is of shape $(d+1, 1)$ and $\\mathbb{x}$ is of shape $(d+1, n)$ where the first row of $\\mathbb{x}$ has entries as 1.\n"
      ],
      "metadata": {
        "id": "KmF4HhMmhx9R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task \n",
        "\n",
        "Add the dummy feature in the feature matrix `Training_data` and test data matrix `test_data`. We will be using this new feature matrices (after adding te dummy feature) for learning the model.\n",
        "\n",
        "Note: As per your convenience, you can convert the shape of the training dataset to $(d, n)$. "
      ],
      "metadata": {
        "id": "kN5fsfqfmX_w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Enter your solution here\n",
        "dummy_feature = np.ones(Training_data.shape[0])\n",
        "Training_data = np.column_stack((Training_data, dummy_feature))\n",
        "Training_data.shape"
      ],
      "metadata": {
        "id": "wic4nhW47fOv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e90677ad-f641-429a-f4b7-26467bf110a4"
      },
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(404, 14)"
            ]
          },
          "metadata": {},
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 4\n",
        "If the solution of optimization problem is obtained by setting the first derivative of loss function (squared loss) to zero, find the value of $w_0+w_1+...w_d$.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "sK4oWgqCnzgc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Enter your solution here\n",
        "X = Training_data\n",
        "y = labels\n",
        "weight = (np.linalg.inv((X.T @ X)) @ X.T) @ y\n",
        "weight.sum()"
      ],
      "metadata": {
        "id": "JORYNRkdOo55",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5eaa5df4-5ad5-4942-f389-f661bc66e4a0"
      },
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20.524582464650628"
            ]
          },
          "metadata": {},
          "execution_count": 180
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 5\n",
        "Find the average of the predictions made by the above model.\n",
        "\n"
      ],
      "metadata": {
        "id": "uBUor5KWp3_Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Enter your solution here\n",
        "training_prediction = Training_data @ weight\n",
        "training_prediction.mean()"
      ],
      "metadata": {
        "id": "O2vF1aE2Rxfs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cef70de4-17cc-4f1e-b88b-4d5ad28898d2"
      },
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "22.30915841584094"
            ]
          },
          "metadata": {},
          "execution_count": 181
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 6\n",
        "\n",
        "Find the loss for the training data points using the above model. Consider the loss to be defined as\n",
        "\n",
        "$$ \\sqrt{\\dfrac{1}{n}\\sum\\limits_{i=1}^{n} (y_i- \\hat{y}_i)^2}\n",
        "$$\n",
        "\n",
        "Where $\\hat{y}_i$ is the prediction for $i^{th}$ data point. \n",
        "\n"
      ],
      "metadata": {
        "id": "FSDbBz7ucm_a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Enter your solution here\n",
        "error2 = (labels - training_prediction)**2\n",
        "loss = np.sqrt(error2.mean())\n",
        "loss"
      ],
      "metadata": {
        "id": "F4jRui2VSeDt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b64c0460-11c3-4175-892f-85d1a065be70"
      },
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.552387969840813"
            ]
          },
          "metadata": {},
          "execution_count": 182
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 7\n",
        "\n",
        "Find the loss for the test data points using the above model. Consider the loss to be defined as\n",
        "\n",
        "$$ \\sqrt{\\dfrac{1}{n}\\sum\\limits_{i=1}^{n} (y_i- \\hat{y}_i)^2}\n",
        "$$\n",
        "\n",
        "Where $\\hat{y}_i$ is the prediction for $i^{th}$ data point. \n",
        "\n"
      ],
      "metadata": {
        "id": "5eh8cI4PeVEb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Enter your solution here\n",
        "dummy_feature = np.ones(Test_data.shape[0])\n",
        "Test_data = np.column_stack((Test_data, dummy_feature))\n",
        "test_prediction = Test_data @ weight\n",
        "\n",
        "error2 = (test_labels - test_prediction)**2\n",
        "loss = np.sqrt(error2.mean())\n",
        "loss"
      ],
      "metadata": {
        "id": "vBMCgEIBU6v5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45a3a49b-c69c-461b-f410-2e52b7efb8be"
      },
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5.327662216181837"
            ]
          },
          "metadata": {},
          "execution_count": 183
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 8\n",
        "Find the weights using the gradient descent. Use a constant learning rate of $\\eta = 10^{-10}$. Initialize the weight vector as zero vector and update the weights for 100 iterations. Enter the sum of all the weights.\n",
        "\n"
      ],
      "metadata": {
        "id": "NkeClcplfJLK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Enter your solution here\n",
        "X = Training_data\n",
        "y = labels\n",
        "\n",
        "n = X.shape[0]\n",
        "d = X.shape[1]\n",
        "lr = 10**(-10)\n",
        "\n",
        "weights = np.zeros(d)\n",
        "for i in range(100):\n",
        "  #print(f\"Iteration {i+1}\")\n",
        "  weights = weights - lr * ((2 * ((X.T @ X) @ weights)) - 2 * X.T @ y)\n",
        "weights.sum()"
      ],
      "metadata": {
        "id": "QbpyGnfgWEqj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d837e55-1876-4af9-fd37-ffc1896988cd"
      },
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.058959061195902635"
            ]
          },
          "metadata": {},
          "execution_count": 184
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Training_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P83mC2xLJrYu",
        "outputId": "c1a367e4-e6fe-4d74-db4f-f2d77a0da969"
      },
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(404, 14)"
            ]
          },
          "metadata": {},
          "execution_count": 185
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 9\n",
        "\n",
        "Find the loss for the training data points if the model is learnt using the gradient descent as in question 8. Consider the loss to be defined as\n",
        "\n",
        "$$ \\sqrt{\\dfrac{1}{n}\\sum\\limits_{i=1}^{n} (y_i- \\hat{y}_i)^2}\n",
        "$$\n",
        "\n",
        "Where $\\hat{y}_i$ is the prediction for $i^{th}$ data point. \n",
        "\n"
      ],
      "metadata": {
        "id": "78ApH0oAg96X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Enter your solution here\n",
        "training_prediction = X @ weights\n",
        "\n",
        "error2 = (labels - training_prediction)**2\n",
        "loss = np.sqrt(error2.mean())\n",
        "loss"
      ],
      "metadata": {
        "id": "oI1yIf9N8la7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3c64871-d495-42f2-d91a-75927e15c8c5"
      },
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11.137273237021954"
            ]
          },
          "metadata": {},
          "execution_count": 186
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 10\n",
        "\n",
        "Find the loss for the test data points if the model is learnt using the gradient descent as in question 8. Consider the loss to be defined as\n",
        "\n",
        "$$ \\sqrt{\\dfrac{1}{n}\\sum\\limits_{i=1}^{n} (y_i- \\hat{y}_i)^2}\n",
        "$$\n",
        "\n",
        "Where $\\hat{y}_i$ is the prediction for $i^{th}$ data point. \n",
        "\n"
      ],
      "metadata": {
        "id": "FA7UKT1Y3PXa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Enter your solution here\n",
        "test_prediction = Test_data @ weights\n",
        "\n",
        "error2 = (test_labels - test_prediction)**2\n",
        "loss = np.sqrt(error2.mean())\n",
        "loss"
      ],
      "metadata": {
        "id": "tevVzIIj3SZj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6be9815-fc8f-4f69-9464-a1458bf92ca4"
      },
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10.964491250062142"
            ]
          },
          "metadata": {},
          "execution_count": 187
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 11\n",
        "Find the weights using the stochastic gradient descent. Use a constant learning rate of $\\eta = 10^{-8}$. Initialize the weight vector as zero vector and update the weights for 1000 iterations. . Take the batch size of $⌈\\text{number of samples}/5⌉ $. For sampling the batch examples in $ith$ iteration, set seed at $i$. The final weight is the last updated weight. Do not take the avearge of weights updated in all the iterations. Enter the sum of all the weights.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-AoLsBKc31Ul"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Enter your solution here \n",
        "X = Training_data\n",
        "y = labels\n",
        "n = X.shape[0]\n",
        "d = X.shape[1]\n",
        "lr = 10**(-8)\n",
        "W = np.zeros(d)\n",
        "\n",
        "for i in range(1000):\n",
        "  rng = np.random.default_rng(seed = i)\n",
        "  samples = rng.integers(0, n, size = n//5)\n",
        "  X_s = X[samples]\n",
        "  y_s = y[samples]\n",
        "\n",
        "  W = W - lr * ((2 * ((X_s.T @ X_s) @ W)) - 2 * X_s.T @ y_s)\n",
        "\n",
        "W.sum()"
      ],
      "metadata": {
        "id": "R4odop9yF9VY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91e69c31-a38a-422b-858a-a77c530c7191"
      },
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.10124206187312648"
            ]
          },
          "metadata": {},
          "execution_count": 188
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = [[1,2], [2,3], [5,6]]\n",
        "a = np.array(a)\n",
        "a[[0,2]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VssEydc4daPT",
        "outputId": "297a9dc0-6cef-44b6-9934-26c7b942ea6e"
      },
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 2],\n",
              "       [5, 6]])"
            ]
          },
          "metadata": {},
          "execution_count": 189
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 12\n",
        "\n",
        "Find the loss for the training data points if the model is learnt using the stochastic gradient descent as in question 11. Consider the loss to be defined as\n",
        "\n",
        "$$ \\sqrt{\\dfrac{1}{n}\\sum\\limits_{i=1}^{n} (y_i- \\hat{y}_i)^2}\n",
        "$$\n",
        "\n",
        "Where $\\hat{y}_i$ is the prediction for $i^{th}$ data point. \n",
        "\n"
      ],
      "metadata": {
        "id": "yPzJLciH4NrV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Enter your solution here\n",
        "training_prediction = X @ W\n",
        "\n",
        "error2 = (labels - training_prediction)**2\n",
        "loss = np.sqrt(error2.mean())\n",
        "loss"
      ],
      "metadata": {
        "id": "w9usLAPeLNkt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9aa2f094-cf1c-491d-9f5e-c83bbe853a22"
      },
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8.6246359251934"
            ]
          },
          "metadata": {},
          "execution_count": 190
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 13\n",
        "\n",
        "Find the loss for the test data points if the model is learnt using the stochastic gradient descent as in question 11. Consider the loss to be defined as\n",
        "\n",
        "$$ \\sqrt{\\dfrac{1}{n}\\sum\\limits_{i=1}^{n} (y_i- \\hat{y}_i)^2}\n",
        "$$\n",
        "\n",
        "Where $\\hat{y}_i$ is the prediction for $i^{th}$ data point. \n"
      ],
      "metadata": {
        "id": "rfeamQM94x_N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Enter your solution here\n",
        "test_prediction = Test_data @ W\n",
        "\n",
        "error2 = (test_labels - test_prediction)**2\n",
        "loss = np.sqrt(error2.mean())\n",
        "loss"
      ],
      "metadata": {
        "id": "oF1xpNH845iH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ba481c3-e4ff-4b6e-a6e6-d247a7f16755"
      },
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8.352305624451189"
            ]
          },
          "metadata": {},
          "execution_count": 191
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 2:\n",
        "\n",
        "**kernel Regression**"
      ],
      "metadata": {
        "id": "muMOKLvY5D9O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will generate the synthetic dataset for the kernel regression problem. Run the following cell to get the following variables:\n",
        "\n",
        "`X` = Training data matrix of shape $(n, d)$. In the given dataset $d = 1$. \n",
        "\n",
        "`y` = label vector corresponding to the training dataset"
      ],
      "metadata": {
        "id": "pDAKRJua6rCU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rng = np.random.default_rng(seed = 101)\n",
        "X = np.arange(-2, 2, 0.01).reshape(-1, 1)\n",
        "y = X**3 + rng.normal(0, 1, X.shape[0]).reshape(-1, 1)\n"
      ],
      "metadata": {
        "id": "_WgICXZSnra0"
      },
      "execution_count": 192,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 14\n",
        "\n",
        "Plot the scatter plot between feature and the labels. Enter your answer as 0.\n",
        "\n"
      ],
      "metadata": {
        "id": "y_-9lyPm8aaj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Enter your solution here\n",
        "plt.scatter(X, y)"
      ],
      "metadata": {
        "id": "B12Nc2Sv80_s",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "d73fab8f-30aa-4eed-b32a-95ca31afce11"
      },
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7fab220ba1d0>"
            ]
          },
          "metadata": {},
          "execution_count": 193
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 15\n",
        "How many examples are there in the training dataset?\n",
        "\n"
      ],
      "metadata": {
        "id": "E3e-gQHg8z8x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Enter your solution here\n",
        "X.shape, y.shape"
      ],
      "metadata": {
        "id": "xGeqMCV57ZJB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a1ef3e2-a3e5-4254-9bbb-d884660a41e9"
      },
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((400, 1), (400, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 194
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task:\n",
        "\n",
        "Add the dummy feature in the feature matrix `X`and reshape it to the shape $(d, n)$."
      ],
      "metadata": {
        "id": "uPifeX-K9zuU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Enter your solution here\n",
        "dummy_feature = np.ones(X.shape[0])\n",
        "X = np.column_stack((dummy_feature, X))\n",
        "X = X.T"
      ],
      "metadata": {
        "id": "yduBBJQgujfE"
      },
      "execution_count": 195,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 16\n",
        "\n",
        "Our task is to apply the kernel regression with polynomial kernel of degree 3. We know that weight vector can be written as\n",
        "\n",
        "$$w = \\phi(\\mathbb{x})\\alpha$$\n",
        "\n",
        "let us call the vector $\\alpha$ as coefficient vector. Find the sum of elements in the coefficient vector.\n",
        "\n"
      ],
      "metadata": {
        "id": "HQtBOQua_HQB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Enter your solution here\n",
        "def poly_kernel(X, degree):\n",
        "  return (X.T@X + 1)**degree\n",
        "\n",
        "def coef(X, y, degree):\n",
        "  K = poly_kernel(X, degree)\n",
        "  return (np.linalg.pinv(K))@y"
      ],
      "metadata": {
        "id": "CVMDkgkNqCBG"
      },
      "execution_count": 196,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alpha = coef(X, y, 3)\n",
        "np.sum(alpha)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLA7IqRqeg4N",
        "outputId": "df4f09de-9d38-4737-a570-d3576fa1c5aa"
      },
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.01781057129417185"
            ]
          },
          "metadata": {},
          "execution_count": 197
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 17\n",
        "\n",
        "Find the sum of the predictions made by the kernel regression model of degree 3.\n",
        "\n"
      ],
      "metadata": {
        "id": "Xq0YtsGjA7IK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "alpha.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5HMRSOj3_bKQ",
        "outputId": "8f2ef624-fae4-4bcf-ba53-08de79dfc478"
      },
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(400, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 198
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Enter your solution here\n",
        "K = poly_kernel(X, 3)\n",
        "predictions = alpha.T @ K\n",
        "predictions.shape"
      ],
      "metadata": {
        "id": "YAqln4GZ05dg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2543311-745c-48b3-eb40-2b08fd49faf2"
      },
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 400)"
            ]
          },
          "metadata": {},
          "execution_count": 199
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions.sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "viXzWTOEtTuE",
        "outputId": "14de4fad-614d-4d36-a880-98f7e4d1107e"
      },
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-25.68690492009182"
            ]
          },
          "metadata": {},
          "execution_count": 200
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 18\n",
        "\n",
        "Find the loss for the training data points. Consider the loss to be defined as\n",
        "\n",
        "$$ \\sqrt{\\dfrac{1}{n}\\sum\\limits_{i=1}^{n} (y_i- \\hat{y}_i)^2}\n",
        "$$\n",
        "\n",
        "Where $\\hat{y}_i$ is the prediction for $i^{th}$ data point. \n",
        "\n"
      ],
      "metadata": {
        "id": "pXRpijIeCcSr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Enter your solution here\n",
        "predictions = predictions.T\n",
        "error2 = (y - predictions)**2\n",
        "loss = np.sqrt(error2.mean())\n",
        "loss"
      ],
      "metadata": {
        "id": "8_i2Th-g1ToW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56b36767-690d-4113-c65d-48578dcf46b0"
      },
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0061212525621972"
            ]
          },
          "metadata": {},
          "execution_count": 201
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test dataset\n",
        "\n",
        "run the following cell to get the test data matrix `X_test` and corresponding label vector `y_test`."
      ],
      "metadata": {
        "id": "nGpw3zpI65rm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rng = np.random.default_rng(seed = 102)\n",
        "Xnew = np.arange(-2, 2, 0.03)\n",
        "ynew = Xnew**3 + rng.normal(0, 1.5, Xnew.shape[0])\n",
        "X_test = np.column_stack((np.ones(Xnew.shape[0]), Xnew.reshape(-1, 1))).T\n",
        "y_test = ynew.reshape(-1, 1)\n",
        "plt.scatter(Xnew,ynew)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "fLNDYH_B67kN",
        "outputId": "78d5a4d0-93be-449d-ae4f-db90ca647bfb"
      },
      "execution_count": 202,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7fab223a4e90>"
            ]
          },
          "metadata": {},
          "execution_count": 202
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 19\n",
        "\n",
        "Find the loss for the test data points. Consider the loss to be defined as\n",
        "\n",
        "$$ \\sqrt{\\dfrac{1}{n}\\sum\\limits_{i=1}^{n} (y_i- \\hat{y}_i)^2}\n",
        "$$\n",
        "\n",
        "Where $\\hat{y}_i$ is the prediction for $i^{th}$ data point. \n",
        "\n"
      ],
      "metadata": {
        "id": "5vlunIBzDI1_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lWe8cLaGrLyW",
        "outputId": "a9c6cf80-f627-48b7-884f-98f39a43de39"
      },
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 400)"
            ]
          },
          "metadata": {},
          "execution_count": 203
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def poly_kernel_vec(x, y, p):\n",
        "  return (x.T @ y + 1)**p"
      ],
      "metadata": {
        "id": "jWQD1KNAsKvT"
      },
      "execution_count": 211,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Enter your solution here\n",
        "n = X.shape[1]\n",
        "n_test = X_test.shape[1]\n",
        "\n",
        "test_pred = np.zeros(n_test)\n",
        "for i in range(n_test):\n",
        "  for j in range(n):\n",
        "    test_pred[i] = test_pred[i] + (alpha[j] * poly_kernel_vec(X[:,j], X_test[:,i], 3))\n",
        "\n",
        "test_pred = test_pred.reshape(-1,1)\n",
        "\n",
        "error2 = (y_test - test_pred)**2\n",
        "loss = np.sqrt(error2.mean())\n",
        "loss"
      ],
      "metadata": {
        "id": "_RxSPslY7joK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4053a665-d730-47fb-fcb7-1684f3a4af2f"
      },
      "execution_count": 220,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.5650996763170157"
            ]
          },
          "metadata": {},
          "execution_count": 220
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "K_pred = poly_kernel_vec(X, X_test, 3)\n",
        "test_pred1 = (alpha.T @ K_pred)\n",
        "\n",
        "test_pred1 = test_pred1.T\n",
        "\n",
        "error2 = (y_test - test_pred1)**2\n",
        "loss = np.sqrt(error2.mean())\n",
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOXm64Yow9IM",
        "outputId": "40bab52a-3663-4eff-84b6-a3d8427f2aa0"
      },
      "execution_count": 212,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.565099676317016"
            ]
          },
          "metadata": {},
          "execution_count": 212
        }
      ]
    }
  ]
}